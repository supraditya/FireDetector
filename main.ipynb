{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x=list()\n",
    "y=list()\n",
    "for i in range(1,111):\n",
    "    img=cv2.imread(\"New Fire Images/%d.jpg\"%i,1)\n",
    "    img=cv2.resize(img,(50,50))\n",
    "    img=np.float32(img)\n",
    "    img/=255.0\n",
    "    img = img.reshape(50, 50, 3)\n",
    "    img=img.tolist()\n",
    "    x.append(img)\n",
    "    y.append(1)\n",
    "for i in range(1,543):\n",
    "    img=cv2.imread(\"new normal/%d.jpg\"%i,1)\n",
    "    img=cv2.resize(img,(50,50))\n",
    "    img=np.float32(img)\n",
    "    img/=255.0\n",
    "    img = img.reshape(50, 50, 3)\n",
    "    img=img.tolist()\n",
    "    x.append(img)\n",
    "    y.append(0)\n",
    "x=np.asarray(x)\n",
    "y=np.asarray(y)\n",
    "y=to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def NN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5,5),input_shape=(50,50,3),padding='same', activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(8, (3, 3), activation = 'sigmoid',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = 'sigmoid'))\n",
    "    model.add(Dense(64, activation = 'sigmoid'))\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "    model.compile(Adam(lr = 0.001), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 16)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 158,346\n",
      "Trainable params: 158,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=NN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 652 samples, validate on 652 samples\n",
      "Epoch 1/20\n",
      "652/652 [==============================] - 9s 14ms/step - loss: 0.4667 - acc: 0.8236 - val_loss: 0.4698 - val_acc: 0.8313\n",
      "Epoch 2/20\n",
      "652/652 [==============================] - 2s 4ms/step - loss: 0.4650 - acc: 0.8313 - val_loss: 0.4499 - val_acc: 0.8313\n",
      "Epoch 3/20\n",
      "652/652 [==============================] - 2s 3ms/step - loss: 0.4372 - acc: 0.8344 - val_loss: 0.3978 - val_acc: 0.8497\n",
      "Epoch 4/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3844 - acc: 0.8497 - val_loss: 0.3751 - val_acc: 0.8497\n",
      "Epoch 5/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3668 - acc: 0.8436 - val_loss: 0.3427 - val_acc: 0.8543\n",
      "Epoch 6/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3589 - acc: 0.8374 - val_loss: 0.3326 - val_acc: 0.8574\n",
      "Epoch 7/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3324 - acc: 0.8589 - val_loss: 0.3437 - val_acc: 0.8466\n",
      "Epoch 8/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.3085 - acc: 0.8788 - val_loss: 0.2600 - val_acc: 0.8957\n",
      "Epoch 9/20\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.2900 - acc: 0.8850 - val_loss: 0.2434 - val_acc: 0.9003\n",
      "Epoch 10/20\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.2595 - acc: 0.8926 - val_loss: 0.2300 - val_acc: 0.9034\n",
      "Epoch 11/20\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.2457 - acc: 0.8926 - val_loss: 0.2440 - val_acc: 0.9003\n",
      "Epoch 12/20\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.2389 - acc: 0.8972 - val_loss: 0.2104 - val_acc: 0.9141\n",
      "Epoch 13/20\n",
      "652/652 [==============================] - 1s 2ms/step - loss: 0.2401 - acc: 0.9034 - val_loss: 0.2467 - val_acc: 0.8972\n",
      "Epoch 14/20\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.2100 - acc: 0.9141 - val_loss: 0.2080 - val_acc: 0.9340\n",
      "Epoch 15/20\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.1921 - acc: 0.9279 - val_loss: 0.1669 - val_acc: 0.9325\n",
      "Epoch 16/20\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.1812 - acc: 0.9264 - val_loss: 0.1506 - val_acc: 0.9371\n",
      "Epoch 17/20\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.1679 - acc: 0.9371 - val_loss: 0.1431 - val_acc: 0.9555\n",
      "Epoch 18/20\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.1460 - acc: 0.9494 - val_loss: 0.1369 - val_acc: 0.9494\n",
      "Epoch 19/20\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.1298 - acc: 0.9571 - val_loss: 0.1436 - val_acc: 0.9479\n",
      "Epoch 20/20\n",
      "652/652 [==============================] - 1s 1ms/step - loss: 0.1375 - acc: 0.9479 - val_loss: 0.1139 - val_acc: 0.9678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11d0003d940>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=20,batch_size=5,verbose=1,shuffle=True,validation_data=(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.03137255, 0.03137255, 0.03137255],\n",
       "         [0.03529412, 0.03529412, 0.03529412],\n",
       "         [0.03137255, 0.03137255, 0.03137255],\n",
       "         ...,\n",
       "         [0.0627451 , 0.04705882, 0.03921569],\n",
       "         [0.0627451 , 0.04313726, 0.03921569],\n",
       "         [0.05882353, 0.04313726, 0.03921569]],\n",
       "\n",
       "        [[0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         ...,\n",
       "         [0.04313726, 0.03529412, 0.03529412],\n",
       "         [0.04313726, 0.03529412, 0.03137255],\n",
       "         [0.04313726, 0.03529412, 0.03137255]],\n",
       "\n",
       "        [[0.00784314, 0.01568628, 0.01960784],\n",
       "         [0.00784314, 0.01568628, 0.01960784],\n",
       "         [0.00784314, 0.01568628, 0.01960784],\n",
       "         ...,\n",
       "         [0.02745098, 0.02745098, 0.02745098],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.02745098, 0.02745098, 0.02745098]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.58039218, 0.51764709, 0.4627451 ],\n",
       "         [0.71764708, 0.64313728, 0.56078434],\n",
       "         [0.89019608, 0.80784315, 0.72549021],\n",
       "         ...,\n",
       "         [0.12156863, 0.12156863, 0.14509805],\n",
       "         [0.17254902, 0.16862746, 0.17647059],\n",
       "         [0.15686275, 0.15294118, 0.16078432]],\n",
       "\n",
       "        [[0.10980392, 0.10588235, 0.09803922],\n",
       "         [0.25882354, 0.20784314, 0.14509805],\n",
       "         [0.76862746, 0.69803923, 0.627451  ],\n",
       "         ...,\n",
       "         [0.11764706, 0.12156863, 0.17254902],\n",
       "         [0.07058824, 0.07450981, 0.09019608],\n",
       "         [0.10588235, 0.11372549, 0.11764706]],\n",
       "\n",
       "        [[0.35294119, 0.30588236, 0.27058825],\n",
       "         [0.74117649, 0.65098041, 0.56078434],\n",
       "         [0.44313726, 0.38431373, 0.33725491],\n",
       "         ...,\n",
       "         [0.76862746, 0.71372551, 0.67843139],\n",
       "         [0.1254902 , 0.13333334, 0.13725491],\n",
       "         [0.07843138, 0.07450981, 0.11372549]]],\n",
       "\n",
       "\n",
       "       [[[0.05098039, 0.03529412, 0.03137255],\n",
       "         [0.06666667, 0.04313726, 0.02745098],\n",
       "         [0.14117648, 0.08627451, 0.04313726],\n",
       "         ...,\n",
       "         [0.47843137, 0.57647061, 0.87843138],\n",
       "         [0.97254902, 0.84705883, 0.8509804 ],\n",
       "         [0.98039216, 0.86274511, 0.8392157 ]],\n",
       "\n",
       "        [[0.08627451, 0.03921569, 0.02352941],\n",
       "         [0.17254902, 0.12156863, 0.09019608],\n",
       "         [0.55686277, 0.3882353 , 0.21568628],\n",
       "         ...,\n",
       "         [0.48627451, 0.57647061, 0.88235295],\n",
       "         [0.96470588, 0.87450981, 0.86666667],\n",
       "         [0.95686275, 0.85882354, 0.85882354]],\n",
       "\n",
       "        [[0.1882353 , 0.1254902 , 0.04705882],\n",
       "         [0.65882355, 0.42745098, 0.27450982],\n",
       "         [0.71764708, 0.48235294, 0.24705882],\n",
       "         ...,\n",
       "         [0.10588235, 0.32549021, 0.8509804 ],\n",
       "         [0.36470589, 0.43921569, 0.78823531],\n",
       "         [0.3882353 , 0.43921569, 0.78039217]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.10980392, 0.28627452, 0.95294118],\n",
       "         [0.14509805, 0.24705882, 0.90588236],\n",
       "         [0.00784314, 0.03529412, 0.26274511],\n",
       "         ...,\n",
       "         [0.78431374, 0.65098041, 0.58039218],\n",
       "         [0.64705884, 0.51372552, 0.42745098],\n",
       "         [0.69803923, 0.60784316, 0.55686277]],\n",
       "\n",
       "        [[0.11372549, 0.32941177, 0.96862745],\n",
       "         [0.09803922, 0.10196079, 0.38431373],\n",
       "         [0.01960784, 0.        , 0.00392157],\n",
       "         ...,\n",
       "         [0.88627452, 0.80784315, 0.75686276],\n",
       "         [0.1882353 , 0.11764706, 0.06666667],\n",
       "         [0.98431373, 0.86666667, 0.74901962]],\n",
       "\n",
       "        [[0.09411765, 0.10980392, 0.49803922],\n",
       "         [0.        , 0.03529412, 0.07843138],\n",
       "         [0.01568628, 0.01176471, 0.02352941],\n",
       "         ...,\n",
       "         [0.68627453, 0.55686277, 0.49803922],\n",
       "         [0.64705884, 0.53725493, 0.46666667],\n",
       "         [0.80000001, 0.627451  , 0.53333336]]],\n",
       "\n",
       "\n",
       "       [[[0.01176471, 0.        , 0.00784314],\n",
       "         [0.01176471, 0.        , 0.00784314],\n",
       "         [0.01176471, 0.        , 0.00784314],\n",
       "         ...,\n",
       "         [0.01568628, 0.00392157, 0.01176471],\n",
       "         [0.01176471, 0.        , 0.00784314],\n",
       "         [0.01176471, 0.        , 0.00784314]],\n",
       "\n",
       "        [[0.01176471, 0.        , 0.00784314],\n",
       "         [0.01176471, 0.        , 0.00784314],\n",
       "         [0.01176471, 0.        , 0.00784314],\n",
       "         ...,\n",
       "         [0.01568628, 0.00392157, 0.01176471],\n",
       "         [0.01568628, 0.00392157, 0.01176471],\n",
       "         [0.01568628, 0.00392157, 0.01176471]],\n",
       "\n",
       "        [[0.01176471, 0.        , 0.00784314],\n",
       "         [0.01176471, 0.        , 0.00784314],\n",
       "         [0.01176471, 0.        , 0.00784314],\n",
       "         ...,\n",
       "         [0.01568628, 0.00392157, 0.01176471],\n",
       "         [0.01568628, 0.00392157, 0.01176471],\n",
       "         [0.01176471, 0.        , 0.00784314]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.02745098, 0.01960784, 0.0627451 ],\n",
       "         [0.        , 0.01176471, 0.05098039],\n",
       "         [0.03529412, 0.03529412, 0.08235294],\n",
       "         ...,\n",
       "         [0.        , 0.03529412, 0.21176471],\n",
       "         [0.01568628, 0.01176471, 0.04705882],\n",
       "         [0.00392157, 0.00392157, 0.02352941]],\n",
       "\n",
       "        [[0.03921569, 0.01960784, 0.03921569],\n",
       "         [0.05098039, 0.01568628, 0.00392157],\n",
       "         [0.03529412, 0.01568628, 0.03529412],\n",
       "         ...,\n",
       "         [0.01960784, 0.03529412, 0.1254902 ],\n",
       "         [0.        , 0.00392157, 0.01960784],\n",
       "         [0.00784314, 0.01176471, 0.02745098]],\n",
       "\n",
       "        [[0.03921569, 0.00784314, 0.03529412],\n",
       "         [0.        , 0.03529412, 0.14117648],\n",
       "         [0.01960784, 0.01960784, 0.07450981],\n",
       "         ...,\n",
       "         [0.06666667, 0.07843138, 0.1254902 ],\n",
       "         [0.        , 0.00392157, 0.01960784],\n",
       "         [0.00392157, 0.00784314, 0.02352941]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.90588236, 0.81568629, 0.76862746],\n",
       "         [0.90588236, 0.82352942, 0.77254903],\n",
       "         [0.89803922, 0.82352942, 0.80784315],\n",
       "         ...,\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843]],\n",
       "\n",
       "        [[0.89411765, 0.83137256, 0.78039217],\n",
       "         [0.89803922, 0.81568629, 0.78823531],\n",
       "         [0.89803922, 0.82745099, 0.78431374],\n",
       "         ...,\n",
       "         [0.88627452, 0.90980393, 0.89019608],\n",
       "         [0.78431374, 0.83137256, 0.83137256],\n",
       "         [0.79215688, 0.82352942, 0.82352942]],\n",
       "\n",
       "        [[0.89411765, 0.81960785, 0.80000001],\n",
       "         [0.90196079, 0.8392157 , 0.81568629],\n",
       "         [0.87843138, 0.83529413, 0.79215688],\n",
       "         ...,\n",
       "         [0.7647059 , 0.79215688, 0.79215688],\n",
       "         [0.72549021, 0.76078433, 0.77254903],\n",
       "         [0.71764708, 0.74901962, 0.74509805]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.08235294, 0.07058824, 0.05098039],\n",
       "         [0.08627451, 0.06666667, 0.05490196],\n",
       "         [0.10196079, 0.08235294, 0.07058824],\n",
       "         ...,\n",
       "         [0.13333334, 0.11372549, 0.09411765],\n",
       "         [0.12156863, 0.10196079, 0.09019608],\n",
       "         [0.14509805, 0.12156863, 0.10588235]],\n",
       "\n",
       "        [[0.08627451, 0.07450981, 0.05490196],\n",
       "         [0.09803922, 0.08235294, 0.0627451 ],\n",
       "         [0.07843138, 0.06666667, 0.04705882],\n",
       "         ...,\n",
       "         [0.1254902 , 0.10196079, 0.08627451],\n",
       "         [0.11372549, 0.09411765, 0.08235294],\n",
       "         [0.10588235, 0.08627451, 0.07450981]],\n",
       "\n",
       "        [[0.09411765, 0.08235294, 0.06666667],\n",
       "         [0.07843138, 0.05882353, 0.04705882],\n",
       "         [0.07450981, 0.0627451 , 0.04705882],\n",
       "         ...,\n",
       "         [0.10196079, 0.08627451, 0.06666667],\n",
       "         [0.12156863, 0.10196079, 0.09019608],\n",
       "         [0.10980392, 0.09019608, 0.07843138]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.00392157],\n",
       "         [0.03921569, 0.        , 0.00784314],\n",
       "         ...,\n",
       "         [0.00392157, 0.00784314, 0.        ],\n",
       "         [0.03529412, 0.05098039, 0.08627451],\n",
       "         [0.        , 0.        , 0.00392157]],\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.02352941, 0.00392157, 0.00784314],\n",
       "         [0.        , 0.00784314, 0.        ],\n",
       "         ...,\n",
       "         [0.01960784, 0.        , 0.        ],\n",
       "         [0.0627451 , 0.09411765, 0.12941177],\n",
       "         [0.        , 0.        , 0.01568628]],\n",
       "\n",
       "        [[0.01176471, 0.        , 0.03921569],\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.07843138, 0.10588235, 0.16078432],\n",
       "         [0.00784314, 0.01176471, 0.02745098]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.00784314],\n",
       "         [0.03921569, 0.01960784, 0.02352941],\n",
       "         [0.07058824, 0.04313726, 0.03921569],\n",
       "         ...,\n",
       "         [0.16078432, 0.22745098, 0.3882353 ],\n",
       "         [0.02745098, 0.09019608, 0.20392157],\n",
       "         [0.        , 0.1254902 , 0.25098041]],\n",
       "\n",
       "        [[0.72156864, 0.48235294, 0.29019609],\n",
       "         [0.03137255, 0.01176471, 0.00784314],\n",
       "         [0.04705882, 0.02352941, 0.02352941],\n",
       "         ...,\n",
       "         [0.29019609, 0.4509804 , 0.72549021],\n",
       "         [0.11764706, 0.36862746, 0.68627453],\n",
       "         [0.01960784, 0.01176471, 0.03529412]],\n",
       "\n",
       "        [[0.47450981, 0.27058825, 0.14117648],\n",
       "         [0.77254903, 0.47843137, 0.27843139],\n",
       "         [0.03137255, 0.01960784, 0.03529412],\n",
       "         ...,\n",
       "         [0.18039216, 0.23529412, 0.48235294],\n",
       "         [0.01176471, 0.09411765, 0.19607843],\n",
       "         [0.        , 0.00392157, 0.02745098]]],\n",
       "\n",
       "\n",
       "       [[[0.06666667, 0.09803922, 0.12156863],\n",
       "         [0.11372549, 0.1254902 , 0.15686275],\n",
       "         [0.05490196, 0.07058824, 0.09019608],\n",
       "         ...,\n",
       "         [0.15294118, 0.17647059, 0.19607843],\n",
       "         [0.01960784, 0.02352941, 0.02352941],\n",
       "         [0.02745098, 0.03137255, 0.03921569]],\n",
       "\n",
       "        [[0.47843137, 0.50196081, 0.52941179],\n",
       "         [0.11372549, 0.1254902 , 0.15686275],\n",
       "         [0.05098039, 0.07450981, 0.09411765],\n",
       "         ...,\n",
       "         [0.10980392, 0.13333334, 0.15294118],\n",
       "         [0.01960784, 0.03529412, 0.03921569],\n",
       "         [0.06666667, 0.04313726, 0.04705882]],\n",
       "\n",
       "        [[0.05098039, 0.07843138, 0.10196079],\n",
       "         [0.29411766, 0.39607844, 0.47450981],\n",
       "         [0.09803922, 0.11372549, 0.14509805],\n",
       "         ...,\n",
       "         [0.10588235, 0.1254902 , 0.14509805],\n",
       "         [0.03137255, 0.02352941, 0.03137255],\n",
       "         [0.03137255, 0.02745098, 0.02745098]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.02745098, 0.01960784, 0.01960784],\n",
       "         [0.10196079, 0.14117648, 0.16862746],\n",
       "         [0.03529412, 0.05490196, 0.05098039],\n",
       "         ...,\n",
       "         [0.0627451 , 0.07843138, 0.13333334],\n",
       "         [0.60000002, 0.88627452, 0.96470588],\n",
       "         [0.03137255, 0.03921569, 0.04313726]],\n",
       "\n",
       "        [[0.01960784, 0.01176471, 0.01176471],\n",
       "         [0.03529412, 0.05882353, 0.07843138],\n",
       "         [0.03137255, 0.05098039, 0.04705882],\n",
       "         ...,\n",
       "         [0.01568628, 0.04705882, 0.04705882],\n",
       "         [0.39215687, 0.72941178, 0.94117647],\n",
       "         [0.00784314, 0.02745098, 0.03137255]],\n",
       "\n",
       "        [[0.01176471, 0.00784314, 0.01568628],\n",
       "         [0.02745098, 0.03921569, 0.05098039],\n",
       "         [0.03137255, 0.05098039, 0.05490196],\n",
       "         ...,\n",
       "         [0.0627451 , 0.09019608, 0.13725491],\n",
       "         [0.34117648, 0.64705884, 0.80392158],\n",
       "         [0.02352941, 0.03921569, 0.03137255]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04304338, 0.9569566 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x[76].reshape(1,50,50,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('val96.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
