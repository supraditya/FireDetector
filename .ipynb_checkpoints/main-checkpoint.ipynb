{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sagnik106/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sagnik106/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sagnik106/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sagnik106/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sagnik106/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sagnik106/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sagnik106/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sagnik106/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sagnik106/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sagnik106/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sagnik106/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sagnik106/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x=list()\n",
    "y=list()\n",
    "for i in range(1,1101):\n",
    "    img=cv2.imread(\"Fire 1/%d.jpg\"%i,1)\n",
    "    img=cv2.resize(img,(50,50))\n",
    "    img=np.float32(img)\n",
    "    img/=255.0\n",
    "    img = img.reshape(50, 50, 3)\n",
    "    img=img.tolist()\n",
    "    x.append(img)\n",
    "    y.append(1)\n",
    "for i in range(1,543):\n",
    "    img=cv2.imread(\"new normal/%d.jpg\"%i,1)\n",
    "    img=cv2.resize(img,(50,50))\n",
    "    img=np.float32(img)\n",
    "    img/=255.0\n",
    "    img = img.reshape(50, 50, 3)\n",
    "    img=img.tolist()\n",
    "    x.append(img)\n",
    "    y.append(0)\n",
    "x=np.asarray(x)\n",
    "y=np.asarray(y)\n",
    "y=to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def NN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5,5),input_shape=(50,50,3),padding='same', activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(8, (3, 3), activation = 'sigmoid',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = 'sigmoid'))\n",
    "    model.add(Dense(64, activation = 'sigmoid'))\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "    model.compile(Adam(lr = 0.001), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sagnik106/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 16)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 25, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 158,346\n",
      "Trainable params: 158,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=NN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sagnik106/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/sagnik106/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1642 samples, validate on 1642 samples\n",
      "Epoch 1/17\n",
      "1642/1642 [==============================] - 3s 2ms/step - loss: 0.5718 - accuracy: 0.7101 - val_loss: 0.4262 - val_accuracy: 0.8149\n",
      "Epoch 2/17\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.4309 - accuracy: 0.8203 - val_loss: 0.4065 - val_accuracy: 0.8216\n",
      "Epoch 3/17\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.3894 - accuracy: 0.8362 - val_loss: 0.4320 - val_accuracy: 0.8258\n",
      "Epoch 4/17\n",
      "1642/1642 [==============================] - 2s 1ms/step - loss: 0.3731 - accuracy: 0.8429 - val_loss: 0.3343 - val_accuracy: 0.8538\n",
      "Epoch 5/17\n",
      "1642/1642 [==============================] - 3s 2ms/step - loss: 0.3326 - accuracy: 0.8587 - val_loss: 0.3259 - val_accuracy: 0.8581\n",
      "Epoch 6/17\n",
      "1642/1642 [==============================] - 3s 2ms/step - loss: 0.3105 - accuracy: 0.8776 - val_loss: 0.2797 - val_accuracy: 0.8959\n",
      "Epoch 7/17\n",
      "1642/1642 [==============================] - 2s 2ms/step - loss: 0.2832 - accuracy: 0.8916 - val_loss: 0.2473 - val_accuracy: 0.9044\n",
      "Epoch 8/17\n",
      "1642/1642 [==============================] - 3s 2ms/step - loss: 0.2638 - accuracy: 0.8965 - val_loss: 0.2300 - val_accuracy: 0.9135\n",
      "Epoch 9/17\n",
      "1642/1642 [==============================] - 3s 2ms/step - loss: 0.2313 - accuracy: 0.9068 - val_loss: 0.2294 - val_accuracy: 0.9123\n",
      "Epoch 10/17\n",
      "1642/1642 [==============================] - 3s 2ms/step - loss: 0.2091 - accuracy: 0.9245 - val_loss: 0.1857 - val_accuracy: 0.9294\n",
      "Epoch 11/17\n",
      "1642/1642 [==============================] - 3s 2ms/step - loss: 0.1973 - accuracy: 0.9257 - val_loss: 0.2164 - val_accuracy: 0.9105\n",
      "Epoch 12/17\n",
      "1642/1642 [==============================] - 3s 2ms/step - loss: 0.1723 - accuracy: 0.9348 - val_loss: 0.1338 - val_accuracy: 0.9495\n",
      "Epoch 13/17\n",
      "1642/1642 [==============================] - 2s 2ms/step - loss: 0.1449 - accuracy: 0.9501 - val_loss: 0.1053 - val_accuracy: 0.9629\n",
      "Epoch 14/17\n",
      "1642/1642 [==============================] - 3s 2ms/step - loss: 0.1144 - accuracy: 0.9598 - val_loss: 0.0788 - val_accuracy: 0.9738\n",
      "Epoch 15/17\n",
      "1642/1642 [==============================] - 3s 2ms/step - loss: 0.0934 - accuracy: 0.9714 - val_loss: 0.0674 - val_accuracy: 0.9799\n",
      "Epoch 16/17\n",
      "1642/1642 [==============================] - 3s 2ms/step - loss: 0.0683 - accuracy: 0.9769 - val_loss: 0.0599 - val_accuracy: 0.9775\n",
      "Epoch 17/17\n",
      "1642/1642 [==============================] - 3s 2ms/step - loss: 0.0638 - accuracy: 0.9769 - val_loss: 0.0469 - val_accuracy: 0.9896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7feb6c82cbe0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=17,batch_size=5,verbose=1,shuffle=True,validation_data=(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.03137255, 0.03137255, 0.03137255],\n",
       "         [0.03529412, 0.03529412, 0.03529412],\n",
       "         [0.03137255, 0.03137255, 0.03137255],\n",
       "         ...,\n",
       "         [0.0627451 , 0.04705882, 0.03921569],\n",
       "         [0.0627451 , 0.04313726, 0.03921569],\n",
       "         [0.05882353, 0.04313726, 0.03921569]],\n",
       "\n",
       "        [[0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         ...,\n",
       "         [0.04313726, 0.03529412, 0.03529412],\n",
       "         [0.04313726, 0.03529412, 0.03137255],\n",
       "         [0.04313726, 0.03529412, 0.03137255]],\n",
       "\n",
       "        [[0.00784314, 0.01568628, 0.01960784],\n",
       "         [0.00784314, 0.01568628, 0.01960784],\n",
       "         [0.00784314, 0.01568628, 0.01960784],\n",
       "         ...,\n",
       "         [0.02745098, 0.02745098, 0.02745098],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.02745098, 0.02745098, 0.02745098]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.58039218, 0.51764709, 0.4627451 ],\n",
       "         [0.71764708, 0.64313728, 0.56078434],\n",
       "         [0.89019608, 0.80784315, 0.72549021],\n",
       "         ...,\n",
       "         [0.12156863, 0.12156863, 0.14509805],\n",
       "         [0.17254902, 0.16862746, 0.17647059],\n",
       "         [0.15686275, 0.15294118, 0.16078432]],\n",
       "\n",
       "        [[0.10980392, 0.10588235, 0.09803922],\n",
       "         [0.25882354, 0.20784314, 0.14509805],\n",
       "         [0.76862746, 0.69803923, 0.627451  ],\n",
       "         ...,\n",
       "         [0.11764706, 0.12156863, 0.17254902],\n",
       "         [0.07058824, 0.07450981, 0.09019608],\n",
       "         [0.10588235, 0.11372549, 0.11764706]],\n",
       "\n",
       "        [[0.35294119, 0.30588236, 0.27058825],\n",
       "         [0.74117649, 0.65098041, 0.56078434],\n",
       "         [0.44313726, 0.38431373, 0.33725491],\n",
       "         ...,\n",
       "         [0.76862746, 0.71372551, 0.67843139],\n",
       "         [0.1254902 , 0.13333334, 0.13725491],\n",
       "         [0.07843138, 0.07450981, 0.11372549]]],\n",
       "\n",
       "\n",
       "       [[[0.05098039, 0.03529412, 0.03137255],\n",
       "         [0.06666667, 0.04313726, 0.02745098],\n",
       "         [0.14117648, 0.08627451, 0.04313726],\n",
       "         ...,\n",
       "         [0.47843137, 0.57647061, 0.87843138],\n",
       "         [0.97254902, 0.84705883, 0.8509804 ],\n",
       "         [0.98039216, 0.86274511, 0.8392157 ]],\n",
       "\n",
       "        [[0.08627451, 0.03921569, 0.02352941],\n",
       "         [0.17254902, 0.12156863, 0.09019608],\n",
       "         [0.55686277, 0.3882353 , 0.21568628],\n",
       "         ...,\n",
       "         [0.48627451, 0.57647061, 0.88235295],\n",
       "         [0.96470588, 0.87450981, 0.86666667],\n",
       "         [0.95686275, 0.85882354, 0.85882354]],\n",
       "\n",
       "        [[0.1882353 , 0.1254902 , 0.04705882],\n",
       "         [0.65882355, 0.42745098, 0.27450982],\n",
       "         [0.71764708, 0.48235294, 0.24705882],\n",
       "         ...,\n",
       "         [0.10588235, 0.32549021, 0.8509804 ],\n",
       "         [0.36470589, 0.43921569, 0.78823531],\n",
       "         [0.3882353 , 0.43921569, 0.78039217]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.10980392, 0.28627452, 0.95294118],\n",
       "         [0.14509805, 0.24705882, 0.90588236],\n",
       "         [0.00784314, 0.03529412, 0.26274511],\n",
       "         ...,\n",
       "         [0.78431374, 0.65098041, 0.58039218],\n",
       "         [0.64705884, 0.51372552, 0.42745098],\n",
       "         [0.69803923, 0.60784316, 0.55686277]],\n",
       "\n",
       "        [[0.11372549, 0.32941177, 0.96862745],\n",
       "         [0.09803922, 0.10196079, 0.38431373],\n",
       "         [0.01960784, 0.        , 0.00392157],\n",
       "         ...,\n",
       "         [0.88627452, 0.80784315, 0.75686276],\n",
       "         [0.1882353 , 0.11764706, 0.06666667],\n",
       "         [0.98431373, 0.86666667, 0.74901962]],\n",
       "\n",
       "        [[0.09411765, 0.10980392, 0.49803922],\n",
       "         [0.        , 0.03529412, 0.07843138],\n",
       "         [0.01568628, 0.01176471, 0.02352941],\n",
       "         ...,\n",
       "         [0.68627453, 0.55686277, 0.49803922],\n",
       "         [0.64705884, 0.53725493, 0.46666667],\n",
       "         [0.80000001, 0.627451  , 0.53333336]]],\n",
       "\n",
       "\n",
       "       [[[0.01176471, 0.        , 0.00784314],\n",
       "         [0.01176471, 0.        , 0.00784314],\n",
       "         [0.01176471, 0.        , 0.00784314],\n",
       "         ...,\n",
       "         [0.01568628, 0.00392157, 0.01176471],\n",
       "         [0.01176471, 0.        , 0.00784314],\n",
       "         [0.01176471, 0.        , 0.00784314]],\n",
       "\n",
       "        [[0.01176471, 0.        , 0.00784314],\n",
       "         [0.01176471, 0.        , 0.00784314],\n",
       "         [0.01176471, 0.        , 0.00784314],\n",
       "         ...,\n",
       "         [0.01568628, 0.00392157, 0.01176471],\n",
       "         [0.01568628, 0.00392157, 0.01176471],\n",
       "         [0.01568628, 0.00392157, 0.01176471]],\n",
       "\n",
       "        [[0.01176471, 0.        , 0.00784314],\n",
       "         [0.01176471, 0.        , 0.00784314],\n",
       "         [0.01176471, 0.        , 0.00784314],\n",
       "         ...,\n",
       "         [0.01568628, 0.00392157, 0.01176471],\n",
       "         [0.01568628, 0.00392157, 0.01176471],\n",
       "         [0.01176471, 0.        , 0.00784314]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.02745098, 0.01960784, 0.0627451 ],\n",
       "         [0.        , 0.01176471, 0.05098039],\n",
       "         [0.03529412, 0.03529412, 0.08235294],\n",
       "         ...,\n",
       "         [0.        , 0.03529412, 0.21176471],\n",
       "         [0.01568628, 0.01176471, 0.04705882],\n",
       "         [0.00392157, 0.00392157, 0.02352941]],\n",
       "\n",
       "        [[0.03921569, 0.01960784, 0.03921569],\n",
       "         [0.05098039, 0.01568628, 0.00392157],\n",
       "         [0.03529412, 0.01568628, 0.03529412],\n",
       "         ...,\n",
       "         [0.01960784, 0.03529412, 0.1254902 ],\n",
       "         [0.        , 0.00392157, 0.01960784],\n",
       "         [0.00784314, 0.01176471, 0.02745098]],\n",
       "\n",
       "        [[0.03921569, 0.00784314, 0.03529412],\n",
       "         [0.        , 0.03529412, 0.14117648],\n",
       "         [0.01960784, 0.01960784, 0.07450981],\n",
       "         ...,\n",
       "         [0.06666667, 0.07843138, 0.1254902 ],\n",
       "         [0.        , 0.00392157, 0.01960784],\n",
       "         [0.00392157, 0.00784314, 0.02352941]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.90588236, 0.81568629, 0.76862746],\n",
       "         [0.90588236, 0.82352942, 0.77254903],\n",
       "         [0.89803922, 0.82352942, 0.80784315],\n",
       "         ...,\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843]],\n",
       "\n",
       "        [[0.89411765, 0.83137256, 0.78039217],\n",
       "         [0.89803922, 0.81568629, 0.78823531],\n",
       "         [0.89803922, 0.82745099, 0.78431374],\n",
       "         ...,\n",
       "         [0.88627452, 0.90980393, 0.89019608],\n",
       "         [0.78431374, 0.83137256, 0.83137256],\n",
       "         [0.79215688, 0.82352942, 0.82352942]],\n",
       "\n",
       "        [[0.89411765, 0.81960785, 0.80000001],\n",
       "         [0.90196079, 0.8392157 , 0.81568629],\n",
       "         [0.87843138, 0.83529413, 0.79215688],\n",
       "         ...,\n",
       "         [0.7647059 , 0.79215688, 0.79215688],\n",
       "         [0.72549021, 0.76078433, 0.77254903],\n",
       "         [0.71764708, 0.74901962, 0.74509805]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.08235294, 0.07058824, 0.05098039],\n",
       "         [0.08627451, 0.06666667, 0.05490196],\n",
       "         [0.10196079, 0.08235294, 0.07058824],\n",
       "         ...,\n",
       "         [0.13333334, 0.11372549, 0.09411765],\n",
       "         [0.12156863, 0.10196079, 0.09019608],\n",
       "         [0.14509805, 0.12156863, 0.10588235]],\n",
       "\n",
       "        [[0.08627451, 0.07450981, 0.05490196],\n",
       "         [0.09803922, 0.08235294, 0.0627451 ],\n",
       "         [0.07843138, 0.06666667, 0.04705882],\n",
       "         ...,\n",
       "         [0.1254902 , 0.10196079, 0.08627451],\n",
       "         [0.11372549, 0.09411765, 0.08235294],\n",
       "         [0.10588235, 0.08627451, 0.07450981]],\n",
       "\n",
       "        [[0.09411765, 0.08235294, 0.06666667],\n",
       "         [0.07843138, 0.05882353, 0.04705882],\n",
       "         [0.07450981, 0.0627451 , 0.04705882],\n",
       "         ...,\n",
       "         [0.10196079, 0.08627451, 0.06666667],\n",
       "         [0.12156863, 0.10196079, 0.09019608],\n",
       "         [0.10980392, 0.09019608, 0.07843138]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.00392157],\n",
       "         [0.03921569, 0.        , 0.00784314],\n",
       "         ...,\n",
       "         [0.00392157, 0.00784314, 0.        ],\n",
       "         [0.03529412, 0.05098039, 0.08627451],\n",
       "         [0.        , 0.        , 0.00392157]],\n",
       "\n",
       "        [[0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.02352941, 0.00392157, 0.00784314],\n",
       "         [0.        , 0.00784314, 0.        ],\n",
       "         ...,\n",
       "         [0.01960784, 0.        , 0.        ],\n",
       "         [0.0627451 , 0.09411765, 0.12941177],\n",
       "         [0.        , 0.        , 0.01568628]],\n",
       "\n",
       "        [[0.01176471, 0.        , 0.03921569],\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.07843138, 0.10588235, 0.16078432],\n",
       "         [0.00784314, 0.01176471, 0.02745098]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.00784314],\n",
       "         [0.03921569, 0.01960784, 0.02352941],\n",
       "         [0.07058824, 0.04313726, 0.03921569],\n",
       "         ...,\n",
       "         [0.16078432, 0.22745098, 0.3882353 ],\n",
       "         [0.02745098, 0.09019608, 0.20392157],\n",
       "         [0.        , 0.1254902 , 0.25098041]],\n",
       "\n",
       "        [[0.72156864, 0.48235294, 0.29019609],\n",
       "         [0.03137255, 0.01176471, 0.00784314],\n",
       "         [0.04705882, 0.02352941, 0.02352941],\n",
       "         ...,\n",
       "         [0.29019609, 0.4509804 , 0.72549021],\n",
       "         [0.11764706, 0.36862746, 0.68627453],\n",
       "         [0.01960784, 0.01176471, 0.03529412]],\n",
       "\n",
       "        [[0.47450981, 0.27058825, 0.14117648],\n",
       "         [0.77254903, 0.47843137, 0.27843139],\n",
       "         [0.03137255, 0.01960784, 0.03529412],\n",
       "         ...,\n",
       "         [0.18039216, 0.23529412, 0.48235294],\n",
       "         [0.01176471, 0.09411765, 0.19607843],\n",
       "         [0.        , 0.00392157, 0.02745098]]],\n",
       "\n",
       "\n",
       "       [[[0.06666667, 0.09803922, 0.12156863],\n",
       "         [0.11372549, 0.1254902 , 0.15686275],\n",
       "         [0.05490196, 0.07058824, 0.09019608],\n",
       "         ...,\n",
       "         [0.15294118, 0.17647059, 0.19607843],\n",
       "         [0.01960784, 0.02352941, 0.02352941],\n",
       "         [0.02745098, 0.03137255, 0.03921569]],\n",
       "\n",
       "        [[0.47843137, 0.50196081, 0.52941179],\n",
       "         [0.11372549, 0.1254902 , 0.15686275],\n",
       "         [0.05098039, 0.07450981, 0.09411765],\n",
       "         ...,\n",
       "         [0.10980392, 0.13333334, 0.15294118],\n",
       "         [0.01960784, 0.03529412, 0.03921569],\n",
       "         [0.06666667, 0.04313726, 0.04705882]],\n",
       "\n",
       "        [[0.05098039, 0.07843138, 0.10196079],\n",
       "         [0.29411766, 0.39607844, 0.47450981],\n",
       "         [0.09803922, 0.11372549, 0.14509805],\n",
       "         ...,\n",
       "         [0.10588235, 0.1254902 , 0.14509805],\n",
       "         [0.03137255, 0.02352941, 0.03137255],\n",
       "         [0.03137255, 0.02745098, 0.02745098]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.02745098, 0.01960784, 0.01960784],\n",
       "         [0.10196079, 0.14117648, 0.16862746],\n",
       "         [0.03529412, 0.05490196, 0.05098039],\n",
       "         ...,\n",
       "         [0.0627451 , 0.07843138, 0.13333334],\n",
       "         [0.60000002, 0.88627452, 0.96470588],\n",
       "         [0.03137255, 0.03921569, 0.04313726]],\n",
       "\n",
       "        [[0.01960784, 0.01176471, 0.01176471],\n",
       "         [0.03529412, 0.05882353, 0.07843138],\n",
       "         [0.03137255, 0.05098039, 0.04705882],\n",
       "         ...,\n",
       "         [0.01568628, 0.04705882, 0.04705882],\n",
       "         [0.39215687, 0.72941178, 0.94117647],\n",
       "         [0.00784314, 0.02745098, 0.03137255]],\n",
       "\n",
       "        [[0.01176471, 0.00784314, 0.01568628],\n",
       "         [0.02745098, 0.03921569, 0.05098039],\n",
       "         [0.03137255, 0.05098039, 0.05490196],\n",
       "         ...,\n",
       "         [0.0627451 , 0.09019608, 0.13725491],\n",
       "         [0.34117648, 0.64705884, 0.80392158],\n",
       "         [0.02352941, 0.03921569, 0.03137255]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00561825, 0.9943817 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x[76].reshape(1,50,50,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('val98.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
