{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitc14b080313334961b23a3bac8d6445f1",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#from coffeeshop.coffeeshop import Coffeeshop\n",
    "from tensordash.tensordash import Tensordash\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Non-Enhanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=list()\n",
    "y=list()\n",
    "fire=glob.glob('augmented fire/*.jpg')\n",
    "nfire=glob.glob('augmented no fire/*.jpg')\n",
    "for i in fire:\n",
    "    img=cv2.imread(i,1)\n",
    "    img=cv2.resize(img,(50,50))\n",
    "    img=np.float32(img)\n",
    "    img/=255.0\n",
    "    img = img.reshape(50, 50, 3)\n",
    "    x.append(img)\n",
    "    y.append(1)\n",
    "for j in nfire:\n",
    "    img=cv2.imread(j,1)\n",
    "    img=cv2.resize(img,(50,50))\n",
    "    img=np.float32(img)\n",
    "    img/=255.0\n",
    "    img = img.reshape(50, 50, 3)\n",
    "    x.append(img)\n",
    "    y.append(0)\n",
    "x=np.asarray(x)\n",
    "y=np.asarray(y)\n",
    "y=to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3),input_shape=(50,50,3),padding='same', activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Conv2D(8, (3, 3), activation = 'sigmoid',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = 'sigmoid'))\n",
    "    model.add(Dense(64, activation = 'sigmoid'))\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "    model.compile(Adam(lr = 0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_7 (Conv2D)            (None, 50, 50, 16)        448       \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 25, 25, 16)        0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 25, 25, 8)         1160      \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 12, 12, 8)         0         \n_________________________________________________________________\nflatten_4 (Flatten)          (None, 1152)              0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 128)               147584    \n_________________________________________________________________\ndense_11 (Dense)             (None, 64)                8256      \n_________________________________________________________________\ndense_12 (Dense)             (None, 2)                 130       \n=================================================================\nTotal params: 157,578\nTrainable params: 157,578\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model=NN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 5850 samples, validate on 650 samples\nEpoch 1/12\n5850/5850 [==============================] - 6s 1ms/step - loss: 0.4283 - accuracy: 0.8191 - val_loss: 0.1802 - val_accuracy: 0.9400\nEpoch 2/12\n5850/5850 [==============================] - 7s 1ms/step - loss: 0.3573 - accuracy: 0.8359 - val_loss: 0.2658 - val_accuracy: 0.9462\nEpoch 3/12\n5850/5850 [==============================] - 7s 1ms/step - loss: 0.3105 - accuracy: 0.8720 - val_loss: 0.2090 - val_accuracy: 0.9400\nEpoch 4/12\n5850/5850 [==============================] - 7s 1ms/step - loss: 0.2918 - accuracy: 0.8793 - val_loss: 0.1675 - val_accuracy: 0.9646\nEpoch 5/12\n5850/5850 [==============================] - 6s 1ms/step - loss: 0.2757 - accuracy: 0.8850 - val_loss: 0.2487 - val_accuracy: 0.9200\nEpoch 6/12\n5850/5850 [==============================] - 6s 1ms/step - loss: 0.2592 - accuracy: 0.8896 - val_loss: 0.1455 - val_accuracy: 0.9554\nEpoch 7/12\n5850/5850 [==============================] - 7s 1ms/step - loss: 0.2415 - accuracy: 0.8981 - val_loss: 0.1215 - val_accuracy: 0.9677\nEpoch 8/12\n5850/5850 [==============================] - 7s 1ms/step - loss: 0.2228 - accuracy: 0.9087 - val_loss: 0.1701 - val_accuracy: 0.9462\nEpoch 9/12\n5850/5850 [==============================] - 7s 1ms/step - loss: 0.2083 - accuracy: 0.9156 - val_loss: 0.1273 - val_accuracy: 0.9508\nEpoch 10/12\n5850/5850 [==============================] - 7s 1ms/step - loss: 0.1897 - accuracy: 0.9209 - val_loss: 0.0883 - val_accuracy: 0.9600\nEpoch 11/12\n5850/5850 [==============================] - 7s 1ms/step - loss: 0.1778 - accuracy: 0.9316 - val_loss: 0.1409 - val_accuracy: 0.9462\nEpoch 12/12\n5850/5850 [==============================] - 7s 1ms/step - loss: 0.1540 - accuracy: 0.9409 - val_loss: 0.0772 - val_accuracy: 0.9723\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x7f2a7465fc50>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=12,batch_size=5,verbose=1,shuffle=True,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('tes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}